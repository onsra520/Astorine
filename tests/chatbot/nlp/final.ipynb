{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = \"__init__.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.cuda.amp as amp\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from rapidfuzz import fuzz\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "project_root = Path(__file__).resolve().parents[1]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from utils.ncomp import rlst, srlst, clst, glst, rrlst, dtlst, sslst\n",
    "\n",
    "paths = {\n",
    "    \"processed\": os.path.abspath(f\"{project_root}/data/storage/processed\"),\n",
    "    \"odata\": os.path.abspath(f\"{project_root}/data/storage/processed/final_cleaning.csv\"),\n",
    "}\n",
    "odata = pd.read_csv(paths[\"odata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Neural Network với LayerNorm, Dropout và tối ưu hóa (pruning, TorchScript, FP16)\n",
    "# ---------------------------\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Network nâng cấp với Layer Normalization và Dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_classes, dropout_rate=0.3):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.ln1 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.ln2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.ln1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout1(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.ln2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "\n",
    "    def optimize(self, pruning_amount=0.3):\n",
    "        # Áp dụng pruning cho các lớp Linear\n",
    "        for _, module in self.named_modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                prune.l1_unstructured(module, name='weight', amount=pruning_amount)\n",
    "                prune.remove(module, 'weight')\n",
    "        # Chuyển mô hình sang half precision để tối ưu inference trên GPU\n",
    "        self.half()\n",
    "        # Sử dụng TorchScript để compile mô hình\n",
    "        scripted_model = torch.jit.script(self)\n",
    "        return scripted_model\n",
    "    \n",
    "    def __getstate__(self):\n",
    "        # Lưu lại hyperparameters và state_dict thay vì toàn bộ đối tượng module\n",
    "        state = {\n",
    "            'input_size': self.input_size,\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'num_classes': self.num_classes,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'state_dict': self.state_dict()\n",
    "        }\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        # Khởi tạo lại đối tượng với các tham số đã lưu\n",
    "        self.__init__(state['input_size'], state['hidden_size'], state['num_classes'], state['dropout_rate'])\n",
    "        self.load_state_dict(state['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComponentExtractor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_names=[\"all-mpnet-base-v2\", \"all-MiniLM-L6-v2\"],\n",
    "        thresholds: Dict[str, float] = None,\n",
    "        fuzzy_config: Dict[str, int] = None,\n",
    "        similarity_weights: dict = None,\n",
    "        use_nn: bool = True,\n",
    "        embedding_dim: int = 384,\n",
    "        hidden_size: int = 256,\n",
    "        ensemble_weights: list = None\n",
    "        ) -> None:\n",
    "        # Thiết lập thiết bị: GPU nếu có, ngược lại CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # Tải dữ liệu và mô hình\n",
    "        self.odata = pd.read_csv(paths[\"odata\"])\n",
    "        self.models = [SentenceTransformer(name) for name in model_names]\n",
    "        self.components = self._load_components()\n",
    "        self.df_components = pd.DataFrame.from_dict(self.components, orient=\"index\").transpose()\n",
    "        self.df_components.columns = [col.lower() for col in self.df_components.columns]\n",
    "        \n",
    "        # Precompute embeddings cho từng mô hình, đồng thời chuyển về self.device,\n",
    "        # và nếu cần, sử dụng projection để đưa về không gian chung với chiều = embedding_dim.\n",
    "        self.desired_embedding_dim = embedding_dim\n",
    "        self.model_projections = self._create_model_projections()\n",
    "        self.embeddings = self._precompute_all_embeddings()\n",
    "        self.ensemble_weights = ensemble_weights if ensemble_weights is not None else [0.6, 0.4]\n",
    "        \n",
    "        # sử dụng neural network để học biểu diễn\n",
    "        self.use_nn = use_nn\n",
    "        if self.use_nn:\n",
    "            self.embedding_net = NeuralNetwork(\n",
    "                input_size=self.desired_embedding_dim,\n",
    "                hidden_size=hidden_size,\n",
    "                num_classes=self.desired_embedding_dim,\n",
    "                dropout_rate=0.3\n",
    "            ).to(self.device)\n",
    "            # Tối ưu hóa neural network: pruning, chuyển sang TorchScript và half precision\n",
    "            self.embedding_net = self.embedding_net.optimize(pruning_amount=0.3)\n",
    "        else:\n",
    "            self.embedding_net = None\n",
    "\n",
    "        # Cấu hình ngưỡng: GPU 0.8, CPU 0.75, các cột khác mặc định 0.60 (có thể thay đổi qua file cấu hình)\n",
    "        default_thresholds = {\"gpu\": 50, \"cpu\": 50, \"default\": 0.6}\n",
    "        self.thresholds = thresholds if thresholds is not None else default_thresholds\n",
    "\n",
    "        # Cấu hình fuzzy matching mặc định\n",
    "        default_fuzzy = {\n",
    "            \"brand\": {\"score_cutoff\": 100, \"scorer\": fuzz.token_sort_ratio},\n",
    "            \"gpu\": {\"score_cutoff\":60, \"scorer\": fuzz.token_sort_ratio},\n",
    "            \"cpu\": {\"score_cutoff\": 60, \"scorer\": fuzz.token_sort_ratio},\n",
    "            \"default\": {\"score_cutoff\": 75, \"scorer\": fuzz.WRatio}\n",
    "        }\n",
    "        self.fuzzy_config = fuzzy_config if fuzzy_config is not None else default_fuzzy\n",
    "\n",
    "        # Trọng số kết hợp giữa cosine similarity và fuzzy matching\n",
    "        default_sim_weights = {\"cosine\": 0.3, \"fuzzy\": 0.7}\n",
    "        self.similarity_weights = similarity_weights if similarity_weights is not None else default_sim_weights\n",
    "        \n",
    "    def _load_components(self) -> dict:\n",
    "        \"\"\"Tải và chuẩn hóa danh sách component từ odata và các hàm mẫu.\"\"\"\n",
    "        components = {\n",
    "            \"brand\": [br.lower() for br in self.odata[\"BRAND\"].unique()],\n",
    "            \"gpu\": sorted(glst(), key=len, reverse=False),\n",
    "            \"cpu\": sorted(clst(), key=len, reverse=False),\n",
    "            \"ram\": sorted(rlst(), key=len, reverse=False),\n",
    "            \"resolution\": sorted(srlst(), key=len, reverse=True),\n",
    "            \"refresh rate\": sorted(rrlst(), key=len, reverse=False),\n",
    "            \"display type\": sorted(dtlst(), key=len, reverse=False),\n",
    "            \"screen size\": sorted(sslst(), key=len, reverse=False),\n",
    "        }\n",
    "        return components\n",
    "    \n",
    "    def _create_model_projections(self) -> List[Optional[nn.Linear]]:\n",
    "        projections = []\n",
    "        for model in self.models:\n",
    "            dummy_text = self._clean_text(\"dummy\")\n",
    "            emb = model.encode(dummy_text, convert_to_tensor=True)\n",
    "            current_dim = emb.shape[0]\n",
    "            if current_dim != self.desired_embedding_dim:\n",
    "                proj = nn.Linear(current_dim, self.desired_embedding_dim).to(self.device)\n",
    "                projections.append(proj)\n",
    "            else:\n",
    "                projections.append(None)\n",
    "        return projections\n",
    "    \n",
    "    def _precompute_all_embeddings(self) -> List[Dict[str, torch.Tensor]]:\n",
    "        embeddings = []\n",
    "        for idx, model in enumerate(self.models):\n",
    "            model_emb = {}\n",
    "            proj = self.model_projections[idx]\n",
    "            for comp_type, comp_list in self.components.items():\n",
    "                cleaned = [self._clean_text(text) for text in comp_list]\n",
    "                emb = model.encode(cleaned, convert_to_tensor=True)\n",
    "                if proj is not None:\n",
    "                    emb = proj(emb)\n",
    "                model_emb[comp_type] = emb.to(self.device)\n",
    "            embeddings.append(model_emb)\n",
    "        return embeddings\n",
    "    \n",
    "    def _clean_text(self, text: str=None) -> str:\n",
    "        text = str(text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[\\-/]\", \" \", text)\n",
    "        text = re.sub(r\"[^a-z0-9\\s]\", \"\", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "        return text \n",
    "\n",
    "    def _ensemble_scores(self, scores_list: list) -> torch.Tensor:\n",
    "        weighted = sum(weight * score for weight, score in zip(self.ensemble_weights, scores_list))\n",
    "        return weighted\n",
    "    \n",
    "    def _fuzzy_match(self, candidates: list, query: str, comp_type: str) -> str:\n",
    "        best_candidate = None\n",
    "        best_score = 0\n",
    "        config = self.fuzzy_config.get(comp_type, self.fuzzy_config.get(\"default\"))\n",
    "        cutoff = config.get(\"score_cutoff\", 60)\n",
    "        scorer = config.get(\"scorer\", fuzz.WRatio)\n",
    "        for cand in candidates:\n",
    "            score = scorer(query, cand)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_candidate = cand\n",
    "        if best_score >= cutoff:\n",
    "            return best_candidate\n",
    "        return None\n",
    "\n",
    "    def standardize_component(self, comp_type: str, candidate: str) -> str:\n",
    "        candidate_clean = self._clean_text(candidate)\n",
    "        if comp_type.upper() in self.odata.columns:\n",
    "            canonical_list = self.odata[comp_type.upper()].dropna().unique().tolist()\n",
    "        else:\n",
    "            canonical_list = [candidate]\n",
    "        \n",
    "        best_score = 0.0\n",
    "        best_name = candidate\n",
    "        model = self.models[0]\n",
    "        emb_candidate = model.encode(candidate_clean, convert_to_tensor=True).to(self.device)\n",
    "        for name in canonical_list:\n",
    "            name_clean = self._clean_text(name)\n",
    "            emb_name = model.encode(name_clean, convert_to_tensor=True).to(self.device)\n",
    "            cosine_sim = torch.cosine_similarity(emb_candidate, emb_name, dim=0).item()\n",
    "            fuzzy_score = fuzz.ratio(candidate_clean, name_clean) / 100.0\n",
    "            weighted_score = (self.similarity_weights[\"cosine\"] * cosine_sim +\n",
    "                            self.similarity_weights[\"fuzzy\"] * fuzzy_score)\n",
    "            # Debug: in ra điểm số của candidate so với tên chuẩn\n",
    "            print(f\"[DEBUG] Candidate '{candidate}' vs '{name}': cosine={cosine_sim:.3f}, fuzzy={fuzzy_score:.3f}, weighted={weighted_score:.3f}\")\n",
    "            if weighted_score > best_score:\n",
    "                best_score = weighted_score\n",
    "                best_name = name\n",
    "        \n",
    "        threshold = self.thresholds.get(comp_type, self.thresholds.get(\"default\", 0.60))\n",
    "        print(f\"[DEBUG] Best candidate for '{candidate}' in {comp_type} is '{best_name}' with score {best_score:.3f} (threshold {threshold})\")\n",
    "        return best_name if best_score >= threshold else candidate\n",
    "\n",
    "    \n",
    "    def extract_components(self, query: str) -> dict:\n",
    "        processed_question = self._clean_text(query)\n",
    "        query_embeddings = []\n",
    "        for idx, model in enumerate(self.models):\n",
    "            q_emb = model.encode(processed_question, convert_to_tensor=True)\n",
    "            proj = self.model_projections[idx]\n",
    "            if proj is not None:\n",
    "                q_emb = proj(q_emb)\n",
    "            query_embeddings.append(q_emb.to(self.device))\n",
    "        \n",
    "        result = {}\n",
    "        for comp_type in self.components.keys():\n",
    "            if not self.components[comp_type]:\n",
    "                result[comp_type] = None\n",
    "                continue\n",
    "            \n",
    "            scores_all = []\n",
    "            for idx, emb_dict in enumerate(self.embeddings):\n",
    "                known_emb = emb_dict[comp_type]\n",
    "                if self.use_nn:\n",
    "                    # Sử dụng AMP để tối ưu inference trên GPU với half precision\n",
    "                    with torch.amp.autocast(\"cuda\"):\n",
    "                        refined_known = self.embedding_net(known_emb)\n",
    "                        refined_query = self.embedding_net(query_embeddings[idx].unsqueeze(0)).squeeze(0)\n",
    "                else:\n",
    "                    refined_known = known_emb\n",
    "                    refined_query = query_embeddings[idx]\n",
    "                scores = torch.cosine_similarity(refined_known, refined_query.unsqueeze(0), dim=1)\n",
    "                scores_all.append(scores)\n",
    "            \n",
    "            combined_scores = self._ensemble_scores(scores_all)\n",
    "            best_score, best_idx = torch.max(combined_scores, dim=0)\n",
    "            candidate = self.components[comp_type][best_idx.item()] if best_score.item() >= self.thresholds.get(comp_type, self.thresholds.get(\"default\", 0.60)) else None\n",
    "            \n",
    "            # Chuẩn hóa tên component dựa trên odata với phương pháp kết hợp similarity\n",
    "            if candidate:\n",
    "                standardized = self.standardize_component(comp_type, candidate)\n",
    "                result[comp_type] = standardized\n",
    "            else:\n",
    "                candidate = self._fuzzy_match(self.components[comp_type], query, comp_type)\n",
    "                result[comp_type] = candidate\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor = ComponentExtractor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Astorine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
