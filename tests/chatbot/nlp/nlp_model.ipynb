{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = \"Untitled-1.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json5\n",
    "from datasets import Dataset\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "project_root = Path(__file__).resolve().parents[1]\n",
    "sys.path.append(str(project_root))\n",
    "from utils.qgene import generate_text\n",
    "\n",
    "paths = {\n",
    "    \"processed\": os.path.abspath(f\"{project_root}/data/storage/processed\"),\n",
    "    \"qfragments\": os.path.abspath(f\"{project_root}/intents/qfragments.json\"),\n",
    "    \"questions\": os.path.abspath(f\"{project_root}/intents/questions.csv\"),\n",
    "    \"model\": os.path.abspath(f\"{project_root}/models/t5-base\"),\n",
    "    \"tokenizer\": os.path.abspath(f\"{project_root}/models/tokenizer\"),\n",
    "    \"results\": os.path.abspath(f\"{project_root}/training/results\"),\n",
    "}\n",
    "\n",
    "os.makedirs(paths[\"model\"], exist_ok=True)\n",
    "os.makedirs(paths[\"tokenizer\"], exist_ok=True)\n",
    "os.makedirs(paths[\"results\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLPModel:\n",
    "    def __init__(self, datanum: int=1000):\n",
    "        self.spec = pd.read_csv(os.path.join(paths[\"processed\"], \"final_cleaning.csv\"))\n",
    "        self.qfragments = json5.load(open(paths[\"qfragments\"]))\n",
    "        self.questions = generate_text(datanum)\n",
    "        self.model_checkpoint = \"t5-small\"\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(self.model_checkpoint)\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(self.model_checkpoint)\n",
    "        self.rouge = evaluate.load(\"rouge\")\n",
    "        self.tokenized_dataset = self.dataset().map(self.tokenize_function, batched=True)\n",
    "        self.data_collator = DataCollatorForSeq2Seq(self.tokenizer, model=self.model)\n",
    "\n",
    "    def preprocess_data(self, row: pd.Series) -> dict:\n",
    "        return {\n",
    "            \"input_text\": f\"{row['question']}\",\n",
    "            \"target_text\": f\"\"\"\n",
    "                DISPLAY: {row['display']}; \n",
    "                RAM: {row['ram']}; \n",
    "                GPU: {row['gpu']}; \n",
    "                CPU: {row['cpu']}; \n",
    "                REFRESH_RATE: {row['refresh rate']}; \n",
    "                BRAND: {row['brand']}; \n",
    "                PRICE: {row['price']}\n",
    "                \"\"\"\n",
    "        }\n",
    "\n",
    "    def dataset(self):\n",
    "        processed = self.questions.apply(self.preprocess_data, axis=1)\n",
    "        df_processed = pd.DataFrame(list(processed))\n",
    "        return Dataset.from_pandas(df_processed)\n",
    "\n",
    "    def tokenize_function(self, examples):\n",
    "        model_inputs = self.tokenizer(\n",
    "            examples[\"input_text\"],\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        labels = self.tokenizer(\n",
    "            text_target=examples[\"target_text\"],\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "\n",
    "    def compute_metrics(self, eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.where(predictions != -100, predictions, self.tokenizer.pad_token_id)\n",
    "        labels = np.where(labels != -100, labels, self.tokenizer.pad_token_id)\n",
    "\n",
    "        decoded_preds = self.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "        decoded_labels = self.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        rouge_output = self.rouge.compute(\n",
    "            predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"rouge1\": rouge_output[\"rouge1\"].mid.fmeasure,\n",
    "            \"rouge2\": rouge_output[\"rouge2\"].mid.fmeasure,\n",
    "            \"rougeL\": rouge_output[\"rougeL\"].mid.fmeasure,\n",
    "        }\n",
    "\n",
    "    def save_model(self):\n",
    "        self.trainer.save_model(paths[\"model\"])\n",
    "        self.tokenizer.save_pretrained(paths[\"tokenizer\"])\n",
    "\n",
    "    def train(self, save_model: bool=True):\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=paths[\"results\"],\n",
    "            eval_strategy=\"no\",\n",
    "            learning_rate=3e-5,\n",
    "            per_device_train_batch_size=16,\n",
    "            num_train_epochs=1,\n",
    "            weight_decay=0.01,\n",
    "            do_eval=False,\n",
    "            gradient_accumulation_steps=2,\n",
    "            eval_accumulation_steps=2,\n",
    "            fp16=True,\n",
    "        )\n",
    "\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=self.tokenized_dataset,\n",
    "            processing_class=self.tokenizer,\n",
    "            data_collator=self.data_collator,\n",
    "            compute_metrics=self.compute_metrics,\n",
    "        )\n",
    "\n",
    "        self.trainer.train()\n",
    "        if save_model:\n",
    "            self.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Questions generated successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799c8322cdd2454ea308e2d6ba2d0113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 10:49, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NLPModel(datanum=1000).train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
